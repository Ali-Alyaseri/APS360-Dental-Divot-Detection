{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b6e5e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.25.2-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting imutils\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\users\\ali a\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image) (2.0.0)\n",
      "Collecting scipy>=1.11.4 (from scikit-image)\n",
      "  Downloading scipy-1.16.0-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ------------------------- ------------ 41.0/60.8 kB 960.0 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 60.8/60.8 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting networkx>=3.0 (from scikit-image)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=10.1 (from scikit-image)\n",
      "  Downloading pillow-11.3.0-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\ali a\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image) (2.34.1)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2025.6.11-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\ali a\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image) (24.1)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_image-0.25.2-cp311-cp311-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/12.8 MB 3.3 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.3/12.8 MB 3.5 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.5/12.8 MB 3.9 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/12.8 MB 4.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.0/12.8 MB 4.4 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.3/12.8 MB 4.7 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.6/12.8 MB 5.0 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.8/12.8 MB 5.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.1/12.8 MB 5.2 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.5/12.8 MB 5.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.8/12.8 MB 5.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.9/12.8 MB 5.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.2/12.8 MB 5.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.6/12.8 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.9/12.8 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.3/12.8 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.8/12.8 MB 6.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.2/12.8 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.7/12.8 MB 6.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.1/12.8 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.6/12.8 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.2/12.8 MB 7.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.6/12.8 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.3/12.8 MB 7.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.8/12.8 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.2/12.8 MB 7.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.6/12.8 MB 7.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.2/12.8 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.9/12.8 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.6/12.8 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.4/12.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.7.0-cp311-cp311-win_amd64.whl (10.7 MB)\n",
      "   ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.7 MB 10.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/10.7 MB 12.6 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.6/10.7 MB 13.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.3/10.7 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.7/10.7 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.5/10.7 MB 12.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.2/10.7 MB 12.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.0/10.7 MB 13.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.8/10.7 MB 13.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.6/10.7 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.6/10.7 MB 14.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.5/10.7 MB 15.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.3/10.7 MB 15.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.2/10.7 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.7/10.7 MB 16.0 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "   ---------------------------------------- 0.0/307.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 307.7/307.7 kB 18.6 MB/s eta 0:00:00\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.0 MB 16.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.0/2.0 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 14.4 MB/s eta 0:00:00\n",
      "Downloading pillow-11.3.0-cp311-cp311-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.6/7.0 MB 19.5 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.5/7.0 MB 19.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.6/7.0 MB 20.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.7/7.0 MB 21.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.0/7.0 MB 22.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.9/7.0 MB 22.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.9/7.0 MB 22.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 22.3 MB/s eta 0:00:00\n",
      "Downloading scipy-1.16.0-cp311-cp311-win_amd64.whl (38.6 MB)\n",
      "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.7/38.6 MB 22.5 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 1.9/38.6 MB 24.2 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 2.7/38.6 MB 21.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 3.7/38.6 MB 21.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 4.8/38.6 MB 21.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 6.1/38.6 MB 22.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 7.4/38.6 MB 23.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 8.5/38.6 MB 24.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 9.7/38.6 MB 24.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 10.9/38.6 MB 25.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 12.3/38.6 MB 25.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 13.5/38.6 MB 27.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 14.8/38.6 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 16.2/38.6 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 17.7/38.6 MB 28.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 18.9/38.6 MB 28.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 20.4/38.6 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 22.0/38.6 MB 29.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 23.5/38.6 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 25.0/38.6 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 26.4/38.6 MB 31.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 28.0/38.6 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 29.6/38.6 MB 32.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.1/38.6 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 32.8/38.6 MB 32.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/38.6 MB 34.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.3/38.6 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.6 MB 36.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.6/38.6 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.6/38.6 MB 31.2 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tifffile-2025.6.11-py3-none-any.whl (230 kB)\n",
      "   ---------------------------------------- 0.0/230.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 230.8/230.8 kB 14.7 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (pyproject.toml): started\n",
      "  Building wheel for imutils (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25891 sha256=27a13769970a40584b1cc1f98964ec7dc41c0f7ff2bc3d0f95db2ad472ab84bf\n",
      "  Stored in directory: c:\\users\\ali a\\appdata\\local\\pip\\cache\\wheels\\31\\d0\\2c\\87ce38f6052879e5b7b18f0f8b4a10ad2a9d210e908d449f16\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils, tifffile, threadpoolctl, scipy, pillow, networkx, lazy-loader, joblib, scikit-learn, scikit-image\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 9.5.0\n",
      "    Uninstalling Pillow-9.5.0:\n",
      "      Successfully uninstalled Pillow-9.5.0\n",
      "Successfully installed imutils-0.5.4 joblib-1.5.1 lazy-loader-0.4 networkx-3.5 pillow-11.3.0 scikit-image-0.25.2 scikit-learn-1.7.0 scipy-1.16.0 threadpoolctl-3.6.0 tifffile-2025.6.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: install dependencies\n",
    "!pip install scikit-image imutils scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05b51586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\ali a\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opencv-python) (2.0.0)\n",
      "Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "   ---------------------------------------- 0.0/39.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/39.0 MB 4.8 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.4/39.0 MB 30.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 7.6/39.0 MB 69.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 13.0/39.0 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 18.4/39.0 MB 129.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 23.8/39.0 MB 131.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 29.1/39.0 MB 131.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.3/39.0 MB 131.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.0/39.0 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.0/39.0 MB 81.8 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.12.0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dac696fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: imports & paths\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "# ← Update these to match your machine:\n",
    "BASE_DIR = r\"C:\\Users\\Ali A\\Desktop\\School\\APS360\\Project\\APS360-Dental-Divot-Detection\\datasets\\smile\\combined\\meta\"\n",
    "CSV_PATH = os.path.join(BASE_DIR, \"bounding_boxes.csv\")\n",
    "IMAGE_DIR = os.path.join(BASE_DIR, \"images_with_bboxes\")\n",
    "\n",
    "# load your annotations\n",
    "ann_df = pd.read_csv(CSV_PATH)  \n",
    "# must have columns: image_filename, x_min, y_min, x_max, y_max (all normalized between 0 and 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c93dd3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 5355 positive patches and 5355 negative patches.\n"
     ]
    }
   ],
   "source": [
    "def extract_patches(image_dir, ann_df,\n",
    "                    patch_size=(64,64),\n",
    "                    neg_ratio=1.0,\n",
    "                    max_neg_trials=50):\n",
    "    pos, neg = [], []\n",
    "\n",
    "    # detect whether CSV values look normalized (<1) or absolute (>1)\n",
    "    abs_vals = ann_df[['x_min','y_min','x_max','y_max']].max().max() > 1\n",
    "\n",
    "    for fname, group in ann_df.groupby('image_filename'):\n",
    "        img_path = os.path.join(image_dir, fname)\n",
    "        if not os.path.isfile(img_path):\n",
    "            continue\n",
    "        img = io.imread(img_path, as_gray=True)\n",
    "        H, W = img.shape\n",
    "\n",
    "        bboxes = []\n",
    "        for _, r in group.iterrows():\n",
    "            # skip NaNs\n",
    "            if pd.isnull(r.x_min) or pd.isnull(r.y_min) \\\n",
    "            or pd.isnull(r.x_max) or pd.isnull(r.y_max):\n",
    "                continue\n",
    "\n",
    "            if abs_vals:\n",
    "                # already pixels\n",
    "                x1, y1 = int(r.x_min), int(r.y_min)\n",
    "                x2, y2 = int(r.x_max), int(r.y_max)\n",
    "            else:\n",
    "                # normalized in [0,1]\n",
    "                x1 = int(r.x_min * W)\n",
    "                y1 = int(r.y_min * H)\n",
    "                x2 = int(r.x_max * W)\n",
    "                y2 = int(r.y_max * H)\n",
    "\n",
    "            # sanity checks\n",
    "            if x2 <= x1 or y2 <= y1:\n",
    "                continue\n",
    "            # clip to image bounds\n",
    "            x1, y1 = max(0,x1), max(0,y1)\n",
    "            x2, y2 = min(W,x2), min(H,y2)\n",
    "\n",
    "            bboxes.append((x1, y1, x2, y2))\n",
    "\n",
    "        # positive patches\n",
    "        for x1, y1, x2, y2 in bboxes:\n",
    "            patch = img[y1:y2, x1:x2]\n",
    "            if patch.size == 0:\n",
    "                continue\n",
    "            pos.append(resize(patch, patch_size))\n",
    "\n",
    "        # negative patches\n",
    "        for _ in range(int(len(bboxes) * neg_ratio)):\n",
    "            for _ in range(max_neg_trials):\n",
    "                x = random.randint(0, W - patch_size[1])\n",
    "                y = random.randint(0, H - patch_size[0])\n",
    "                rect = (x, y, x + patch_size[1], y + patch_size[0])\n",
    "\n",
    "                # simple IoU  \n",
    "                def iou(a, b):\n",
    "                    xa, ya = max(a[0], b[0]), max(a[1], b[1])\n",
    "                    xb, yb = min(a[2], b[2]), min(a[3], b[3])\n",
    "                    inter = max(0, xb - xa) * max(0, yb - ya)\n",
    "                    A = (a[2] - a[0]) * (a[3] - a[1])\n",
    "                    B = (b[2] - b[0]) * (b[3] - b[1])\n",
    "                    return inter / (A + B - inter) if inter > 0 else 0\n",
    "\n",
    "                if all(iou(rect, bb) < 0.1 for bb in bboxes):\n",
    "                    neg_patch = img[y:y + patch_size[0], x:x + patch_size[1]]\n",
    "                    if neg_patch.size == 0:\n",
    "                        continue\n",
    "                    neg.append(resize(neg_patch, patch_size))\n",
    "                    break\n",
    "\n",
    "    return pos, neg\n",
    "\n",
    "pos_patches, neg_patches = extract_patches(IMAGE_DIR, ann_df)\n",
    "print(f\"Got {len(pos_patches)} positive patches and {len(neg_patches)} negative patches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08522726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 5355\n",
      "Rows with any NaN in bbox coords: 0\n",
      "Unique filenames: 973\n",
      "Sample filenames: ['dc1000_195.png' 'dc1000_181.png'\n",
      " 'dental_radiography_0078_jpg.rf.3df5e76aaf3853ffeb55283ed9666c1e.jpg'\n",
      " 'dc1000_630.png' 'dc1000_156.png' 'dc1000_142.png' 'dc1000_624.png'\n",
      " 'dental_radiography_0054_jpg.rf.b81c1de4282e2881bc92f9d5b6ca106f.jpg'\n",
      " 'opg_xray_5.jpg' 'dc1000_618.png']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Total rows:\", len(ann_df))\n",
    "print(\"Rows with any NaN in bbox coords:\", \n",
    "      ann_df[['x_min','y_min','x_max','y_max']].isnull().any(axis=1).sum())\n",
    "\n",
    "print(\"Unique filenames:\", ann_df['image_filename'].nunique())\n",
    "print(\"Sample filenames:\", ann_df['image_filename'].unique()[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccc70e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (8568, 1764) 4284.0 positives\n",
      "Test set:  (2142, 1764) 1071.0 positives\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: HOG feature extraction & dataset prep\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def compute_hog_features(patches):\n",
    "    return np.array([\n",
    "        hog(p,\n",
    "            orientations=9,\n",
    "            pixels_per_cell=(8,8),\n",
    "            cells_per_block=(2,2),\n",
    "            block_norm='L2-Hys')\n",
    "        for p in patches\n",
    "    ])\n",
    "\n",
    "X_pos = compute_hog_features(pos_patches)\n",
    "X_neg = compute_hog_features(neg_patches)\n",
    "y_pos = np.ones(len(X_pos))\n",
    "y_neg = np.zeros(len(X_neg))\n",
    "\n",
    "# combine and split\n",
    "X = np.vstack([X_pos, X_neg])\n",
    "y = np.concatenate([y_pos, y_neg])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train set:\", X_train.shape, y_train.sum(), \"positives\")\n",
    "print(\"Test set: \", X_test.shape, y_test.sum(), \"positives\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84d7157b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      1071\n",
      "         1.0       0.99      1.00      0.99      1071\n",
      "\n",
      "    accuracy                           0.99      2142\n",
      "   macro avg       0.99      0.99      0.99      2142\n",
      "weighted avg       0.99      0.99      0.99      2142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: train & evaluate the linear SVM classifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LinearSVC(max_iter=5000, random_state=42)\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1227a0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detections for dc1000_195.png: [[  80   16  144   80]\n",
      " [ 928    0  992   64]\n",
      " [ 160   16  224   80]\n",
      " [ 240    0  304   64]\n",
      " [2816   16 2880   80]\n",
      " [   0    0   64   64]\n",
      " [ 736  560  800  624]\n",
      " [1472  112 1536  176]\n",
      " [2768   16 2832   80]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: sliding-window detector + NMS demo on a real image\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from skimage.transform import resize\n",
    "\n",
    "def sliding_window(img, step, ws):\n",
    "    for y in range(0, img.shape[0] - ws[1] + 1, step):\n",
    "        for x in range(0, img.shape[1] - ws[0] + 1, step):\n",
    "            yield x, y, img[y:y+ws[1], x:x+ws[0]]\n",
    "\n",
    "def detect(img, clf, ws=(64,64), step=16, thresh=0.5):\n",
    "    rects, scores = [], []\n",
    "    for x, y, win in sliding_window(img, step, ws):\n",
    "        feat = hog(resize(win, ws),\n",
    "                   orientations=9,\n",
    "                   pixels_per_cell=(8,8),\n",
    "                   cells_per_block=(2,2),\n",
    "                   block_norm='L2-Hys')\n",
    "        score = clf.decision_function([feat])[0]\n",
    "        if score > thresh:\n",
    "            rects.append((x, y, x+ws[0], y+ws[1]))\n",
    "            scores.append(score)\n",
    "    picks = non_max_suppression(np.array(rects), scores, overlapThresh=0.3)\n",
    "    return picks\n",
    "\n",
    "# choose a sample image from your annotations\n",
    "test_fname = ann_df['image_filename'].iloc[0]\n",
    "test_path  = os.path.join(IMAGE_DIR, test_fname)\n",
    "test_img   = io.imread(test_path, as_gray=True)\n",
    "\n",
    "boxes = detect(test_img, clf)\n",
    "print(f\"Detections for {test_fname}: {boxes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "469d8db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.9930\n",
      "Error rate:       0.0070\n",
      "Confusion matrix (rows=true, cols=predicted):\n",
      "[[1057   14]\n",
      " [   1 1070]]\n",
      "5-fold CV accuracy: 0.9700 ± 0.0551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 5b) overall accuracy & error rate\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "err = 1 - acc\n",
    "print(f\"Overall accuracy: {acc:.4f}\")\n",
    "print(f\"Error rate:       {err:.4f}\")\n",
    "\n",
    "# 5c) confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix (rows=true, cols=predicted):\")\n",
    "print(cm)\n",
    "\n",
    "# Optionally, cross-validation to estimate variance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"5-fold CV accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
